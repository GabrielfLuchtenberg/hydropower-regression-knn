{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Modeling Hydropower Consumption using *k*-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022797,
     "end_time": "2021-01-17T04:47:27.404904",
     "exception": false,
     "start_time": "2021-01-17T04:47:27.382107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018924,
     "end_time": "2021-01-17T04:47:27.444602",
     "exception": false,
     "start_time": "2021-01-17T04:47:27.425678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. [Introduction](#1.-Introduction)\n",
    "\n",
    "1. [Base Libraries](#2.-Base-Libraries)\n",
    "\n",
    "1. [Data Preprocessing](#3.-Data-PreProcessing)\n",
    "\n",
    "2. [Tuning Hyperparameters](#4.-Tuning-Hyperparameters)\n",
    "\n",
    "3. [Validating the Models with Metrics](#5.-Validating-the-Models-with-Metrics)\n",
    "\n",
    "4. [Predicting Energy Generation](#6.-Predicting-Energy-Generation)\n",
    "\n",
    "5. [Conclusions](#7.-Conclusions)\n",
    "\n",
    "6. [References](#8.-References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019178,
     "end_time": "2021-01-17T04:47:27.482982",
     "exception": false,
     "start_time": "2021-01-17T04:47:27.463804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019237,
     "end_time": "2021-01-17T04:47:27.522717",
     "exception": false,
     "start_time": "2021-01-17T04:47:27.503480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For forecasting, historical data is used as input and future trends are predicted on the basis of this data, but accurate selection and extraction of meaningful features from data are challenging. However, the *k*nn algorithm, one of the most simple and useful Machine Learning techniques, can be easily used to generate powerful regression models. In this notebook, I focused on the use of kNN itself and its hyperparametrizations, to guarantee a better understanding of this algorithm and keep it as a plain tutorial to anyone who needs it. Another resources like feature engineering, dimensionality reduction or even another machine learning techniques are not used.\n",
    "\n",
    "The dataset used is a energy generation compilation of several european countries, measured in THh between 2000 and 2019. Its contents were extracted from World in Data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018942,
     "end_time": "2021-01-17T04:47:27.562071",
     "exception": false,
     "start_time": "2021-01-17T04:47:27.543129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Base Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0226,
     "end_time": "2021-01-17T04:47:27.603847",
     "exception": false,
     "start_time": "2021-01-17T04:47:27.581247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First, the basic libraries are imported: **pandas**, **matplotlib** and **numpy** to Dataframes, Graphs and numeric operations; **MinMaxScaler** to normalize our data between 0 and 1, **train_test_split** to help split the dataset (usually 70% training/ 30% testing), **GridSearchCV** for hyperparameter tuning and **neighbors** to generate our models using *k*NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T04:47:27.651212Z",
     "iopub.status.busy": "2021-01-17T04:47:27.650430Z",
     "iopub.status.idle": "2021-01-17T04:47:29.152205Z",
     "shell.execute_reply": "2021-01-17T04:47:29.151258Z"
    },
    "papermill": {
     "duration": 1.528877,
     "end_time": "2021-01-17T04:47:29.152369",
     "exception": false,
     "start_time": "2021-01-17T04:47:27.623492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score, explained_variance_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01925,
     "end_time": "2021-01-17T04:47:29.191503",
     "exception": false,
     "start_time": "2021-01-17T04:47:29.172253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To measure the efficiency of our generated models, we use a bunch of metrics (maybe more than we need):\n",
    "* **mean_absolute_error** (MAE): a measure of errors between paired observations expressing the same phenomenon;\n",
    "* **mean_squared_error**  (root - RMSE): the standard deviation of the residuals (prediction errors);\n",
    "* **mean_squared_log_error** (root - RMSLE): that measures the ratio between actual and predicted;\n",
    "* **r2_score** (R2): coefficient of determination, the proportion of the variance in the dependent variable that is predictable from the independent variable(s); and\n",
    "* **explained_variance_score** (EVS): measures the discrepancy between a model and actual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019273,
     "end_time": "2021-01-17T04:47:29.231103",
     "exception": false,
     "start_time": "2021-01-17T04:47:29.211830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019229,
     "end_time": "2021-01-17T04:47:29.270011",
     "exception": false,
     "start_time": "2021-01-17T04:47:29.250782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Initially, the data is imported from the dataset, and the categorical columns are excluded (in this case, only \"Country\"). To transform the dataset and still keep it as a Dataframe, the *scaler* library is used inside the *Dataframe* library, normalizing the data between 0 and 1, and keeping the dataframe properties. After this, the *describe* function is called, to show some important data about the dataframe, like mean, max, min, std and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-17T04:47:29.333803Z",
     "iopub.status.busy": "2021-01-17T04:47:29.332859Z",
     "iopub.status.idle": "2021-01-17T04:47:29.437076Z",
     "shell.execute_reply": "2021-01-17T04:47:29.436451Z"
    },
    "papermill": {
     "duration": 0.147676,
     "end_time": "2021-01-17T04:47:29.437222",
     "exception": false,
     "start_time": "2021-01-17T04:47:29.289546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1494</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.1168</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.1119</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0514</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.0292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.0661</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.0587</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.0574</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.0321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    2000   2001   2002   2003   2004   2005   2006   2007   2008   2009  \\\n",
       "0 0.0005 0.0008 0.0009 0.0001 0.0009 0.0001 0.0010 0.0012 0.0008 0.0012   \n",
       "1 0.1136 0.1321 0.1347 0.1324 0.1396 0.1358 0.1379 0.1494 0.1455 0.1496   \n",
       "2 0.0069 0.0057 0.0055 0.0082 0.0086 0.0081 0.0074 0.0004 0.0056 0.0078   \n",
       "3 0.0001 0.0001 0.0001 0.0004 0.0004 0.0008 0.0003 0.0004 0.0004 0.0005   \n",
       "4 0.0014 0.0016 0.0018 0.0020 0.0028 0.0033 0.0039 0.0039 0.0046 0.0046   \n",
       "5 0.0514 0.0685 0.0656 0.0062 0.0565 0.0060 0.0652 0.0592 0.0557 0.0611   \n",
       "6 0.0249 0.0263 0.0255 0.0259 0.0251 0.0236 0.0223 0.0205 0.0177 0.0190   \n",
       "7 0.0631 0.0661 0.0636 0.0531 0.0587 0.0565 0.0533 0.0581 0.0574 0.0613   \n",
       "8 0.0023 0.0021 0.0003 0.0004 0.0044 0.0046 0.0038 0.0037 0.0033 0.0035   \n",
       "9 0.0011 0.0016 0.0012 0.0012 0.0012 0.0011 0.0011 0.0012 0.0001 0.0006   \n",
       "\n",
       "    2010   2011   2012   2013   2014   2015   2016   2017   2018   2019  \n",
       "0 0.0011 0.0008 0.0001 0.0009 0.0008 0.0009 0.0009 0.0001 0.0001 0.0001  \n",
       "1 0.1510 0.1517 0.1286 0.1294 0.1168 0.1039 0.1074 0.1119 0.1875 0.0000  \n",
       "2 0.0108 0.0055 0.0055 0.0077 0.0045 0.0053 0.0062 0.0004 0.0006 0.0032  \n",
       "3 0.0002 0.0005 0.0005 0.0001 0.0002 0.0001 0.0001 0.0000 0.0002 0.0001  \n",
       "4 0.0052 0.0054 0.0043 0.0052 0.0047 0.0045 0.0050 0.0065 0.0107 0.0066  \n",
       "5 0.0570 0.0544 0.0427 0.0004 0.0386 0.0375 0.0332 0.0357 0.0588 0.0292  \n",
       "6 0.0193 0.0269 0.0197 0.0210 0.0137 0.0126 0.0153 0.0116 0.0245 0.0113  \n",
       "7 0.0539 0.0470 0.0508 0.0462 0.0039 0.0332 0.0345 0.0329 0.0532 0.0321  \n",
       "8 0.0048 0.0037 0.0021 0.0016 0.0000 0.0015 0.0017 0.0015 0.0025 0.0012  \n",
       "9 0.0010 0.0012 0.0009 0.0008 0.0005 0.0008 0.0008 0.0001 0.0012 0.0006  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the display format\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "# Data Loading and Pre-processing\n",
    "df = pd.read_csv('data/Hydropower_Consumption.csv', sep=',')\n",
    "df = df.drop(columns=[\"Country\"])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df = pd.DataFrame(scaler.fit_transform(df),\n",
    "                        columns=[str(year) for year in range(2000, 2020)])\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022608,
     "end_time": "2021-01-17T04:47:29.483155",
     "exception": false,
     "start_time": "2021-01-17T04:47:29.460547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, my goal was to check the possibility of creating a model that would predict power generation for 2019, based on the previous 18 years (2000 - 2018) with at least 75% accuracy. For this, the data set was separated into X and y, X being my prediction data, and y what I intended to predict. For this, the data set was separated into X and y, X being my prediction data, and y what I intended to predict. For this, they are divided into training (70%) and testing (30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T04:47:29.538414Z",
     "iopub.status.busy": "2021-01-17T04:47:29.537613Z",
     "iopub.status.idle": "2021-01-17T04:47:29.539622Z",
     "shell.execute_reply": "2021-01-17T04:47:29.540111Z"
    },
    "papermill": {
     "duration": 0.034212,
     "end_time": "2021-01-17T04:47:29.540272",
     "exception": false,
     "start_time": "2021-01-17T04:47:29.506060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "X = df.drop(columns=[\"2019\"])\n",
    "y = df[\"2019\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020652,
     "end_time": "2021-01-17T04:47:29.583254",
     "exception": false,
     "start_time": "2021-01-17T04:47:29.562602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since we already have the training and test data selected, it is necessary to find the k factor that will generate the best results for the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023832,
     "end_time": "2021-01-17T04:47:30.373636",
     "exception": false,
     "start_time": "2021-01-17T04:47:30.349804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023134,
     "end_time": "2021-01-17T04:47:30.420010",
     "exception": false,
     "start_time": "2021-01-17T04:47:30.396876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are learned.\n",
    "\n",
    "The same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns. These measures are called hyperparameters, and have to be tuned so that the model can optimally solve the machine learning problem. Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined loss function on given independent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T04:47:30.511076Z",
     "iopub.status.busy": "2021-01-17T04:47:30.489512Z",
     "iopub.status.idle": "2021-01-17T04:47:30.758787Z",
     "shell.execute_reply": "2021-01-17T04:47:30.757972Z"
    },
    "papermill": {
     "duration": 0.316008,
     "end_time": "2021-01-17T04:47:30.758920",
     "exception": false,
     "start_time": "2021-01-17T04:47:30.442912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning using GridSearchCV\n",
    "params = {'n_neighbors': list(range(1, 21))}\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "model = GridSearchCV(knn, params, cv=5)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025484,
     "end_time": "2021-01-17T04:47:30.810801",
     "exception": false,
     "start_time": "2021-01-17T04:47:30.785317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The traditional way of performing hyperparameter optimization has been grid search, or a parameter sweep, which is simply an exhaustive searching through a manually specified subset of the hyperparameter space of a learning algorithm. A grid search algorithm must be guided by some performance metric, typically measured by cross-validation on the training set or evaluation on a held-out validation set. For our dataset, GridSearch indicates 4 as the best values to our *k*, quite similar to our tests realized before.\n",
    "\n",
    "Once you've found the best value for k, it's time to train the model and predict the results. We will also make use of the *score* function, which will allows us to see the accuracy rate for our model (80.16%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T04:47:30.875565Z",
     "iopub.status.busy": "2021-01-17T04:47:30.874080Z",
     "iopub.status.idle": "2021-01-17T04:47:30.887762Z",
     "shell.execute_reply": "2021-01-17T04:47:30.887162Z"
    },
    "papermill": {
     "duration": 0.053727,
     "end_time": "2021-01-17T04:47:30.887877",
     "exception": false,
     "start_time": "2021-01-17T04:47:30.834150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Training and Prediction using the best k value\n",
    "best_k = model.best_params_['n_neighbors']\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors=best_k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033136,
     "end_time": "2021-01-17T04:47:30.956945",
     "exception": false,
     "start_time": "2021-01-17T04:47:30.923809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Once we have the model ready and the prediction made, we can apply the metrics and analyze the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027071,
     "end_time": "2021-01-17T04:47:31.011676",
     "exception": false,
     "start_time": "2021-01-17T04:47:30.984605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Validating the Models with Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02433,
     "end_time": "2021-01-17T04:47:31.060017",
     "exception": false,
     "start_time": "2021-01-17T04:47:31.035687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here the test results are compared with the prediction results within the metrics, so that we can see what the results are for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T04:47:31.120020Z",
     "iopub.status.busy": "2021-01-17T04:47:31.119252Z",
     "iopub.status.idle": "2021-01-17T04:47:31.124259Z",
     "shell.execute_reply": "2021-01-17T04:47:31.125193Z"
    },
    "papermill": {
     "duration": 0.041547,
     "end_time": "2021-01-17T04:47:31.125384",
     "exception": false,
     "start_time": "2021-01-17T04:47:31.083837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K Value: 4\n",
      "R2 Score: 0.8016285342188538\n",
      "Explained Variance Score: 0.8131526313306373\n",
      "Mean Absolute Error: 0.017960057840249434\n",
      "Root Mean Squared Error: 0.04999229884993785\n",
      "Root Mean Squared Log Error: 0.039043708745309796\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics\n",
    "r2_valid = r2_score(y_test, y_pred)\n",
    "mae_valid = mean_absolute_error(y_test, y_pred)\n",
    "evs_valid = explained_variance_score(y_test, y_pred)\n",
    "rmse_valid = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmsle_valid = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "\n",
    "print(f'Best K Value: {best_k}')\n",
    "print('R2 Score:', r2_valid)\n",
    "print('Explained Variance Score:', evs_valid)\n",
    "print('Mean Absolute Error:', mae_valid)\n",
    "print('Root Mean Squared Error:', rmse_valid)\n",
    "print('Root Mean Squared Log Error:', rmsle_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023626,
     "end_time": "2021-01-17T04:47:31.175510",
     "exception": false,
     "start_time": "2021-01-17T04:47:31.151884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The results show an R2 of 80.16% and an EVS of 81.31%, indicating that our model has a great fit to your sample (R2) and a strong association between the model and its current data (EVS). For the RMSLE, it only considers the relative error between and the predicted and the actual value and the scale of the error is not significant. On the other hand, RMSE value increases in magnitude if the scale of error increases. For our model, both presents very low values (4.99% and 3.90%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024467,
     "end_time": "2021-01-17T04:47:31.224224",
     "exception": false,
     "start_time": "2021-01-17T04:47:31.199757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Predicting Energy Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024475,
     "end_time": "2021-01-17T04:47:31.273327",
     "exception": false,
     "start_time": "2021-01-17T04:47:31.248852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Once we have the prediction ready and the model tested, we organize the results side by side to be able to make a comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T04:47:31.336983Z",
     "iopub.status.busy": "2021-01-17T04:47:31.335848Z",
     "iopub.status.idle": "2021-01-17T04:47:31.340797Z",
     "shell.execute_reply": "2021-01-17T04:47:31.340115Z"
    },
    "papermill": {
     "duration": 0.043489,
     "end_time": "2021-01-17T04:47:31.340917",
     "exception": false,
     "start_time": "2021-01-17T04:47:31.297428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.0268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4982</td>\n",
       "      <td>0.3417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.3417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test  Prediction\n",
       "0 0.0406      0.0268\n",
       "1 0.0044      0.0039\n",
       "2 0.0134      0.0096\n",
       "3 0.0280      0.0128\n",
       "4 0.0164      0.0125\n",
       "5 0.0321      0.0155\n",
       "6 0.4982      0.3417\n",
       "7 0.5331      0.3417\n",
       "8 0.0007      0.0075\n",
       "9 0.0032      0.0039"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying Predictions\n",
    "data_prediction = pd.DataFrame(list(zip(y_test, y_pred)), columns=['Test', 'Prediction'])\n",
    "data_prediction.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027413,
     "end_time": "2021-01-17T04:47:31.396492",
     "exception": false,
     "start_time": "2021-01-17T04:47:31.369079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The results presented show a great proximity between the test and prediction values, showing that the model we created managed to fulfill its proposed objective of performing above 75% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027442,
     "end_time": "2021-01-17T04:47:31.451570",
     "exception": false,
     "start_time": "2021-01-17T04:47:31.424128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02737,
     "end_time": "2021-01-17T04:47:31.507004",
     "exception": false,
     "start_time": "2021-01-17T04:47:31.479634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Power generation data sets have a very close pattern, which can be identified even with a simple regression tool, even if the pre-processing of the data is simpler. Several other techniques and algorithms can also be applied to improve the performance of the model at higher levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027697,
     "end_time": "2021-01-17T04:47:31.562425",
     "exception": false,
     "start_time": "2021-01-17T04:47:31.534728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036813,
     "end_time": "2021-01-17T04:47:31.626844",
     "exception": false,
     "start_time": "2021-01-17T04:47:31.590031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[1] Ali, M., Khan, Z. A., Mujeeb, S., Abbas, S., & Javaid, N. (2019). Short-Term Electricity Price and Load Forecasting using Enhanced Support Vector Machine and K-Nearest Neighbor. 2019 Sixth HCT Information Technology Trends (ITT). doi:10.1109/itt48889.2019.9075063 \n",
    "\n",
    "[2] Ashfaq, T., & Javaid, N. (2019). Short-Term Electricity Load and Price Forecasting using Enhanced KNN. 2019 International Conference on Frontiers of Information Technology (FIT). doi:10.1109/fit47737.2019.00057 \n",
    "\n",
    "[3] Chicco, D. (2017). Ten quick tips for machine learning in computational biology. BioData Mining, 10(1). doi:10.1186/s13040-017-0155-3 \n",
    "\n",
    "[4] Claesen, Marc; Bart De Moor (2015). \"Hyperparameter Search in Machine Learning\". arXiv:1502.02127\n",
    "\n",
    "[5] Zaki, M., & Meira, W. (2014). Data Mining and Analysis: Fundamental Concepts and Algorithms. New York City, New York: Cambridge University Press (10.1017/CBO9780511810114)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "duration": 9.903599,
   "end_time": "2021-01-17T04:47:31.761494",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-17T04:47:21.857895",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
